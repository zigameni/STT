 Slajicena redu nam je alata za leksičko nalizu koji ćemo koristiti u izrodi naše prve fase projektnog zadatka. E sad prenego što pređemo na samo specifikaciju i na neka pojašnjenja kako bi vam bilo lakše da koristite sam alat, ja ću vas iši jednomu putiti na sajtu na odiljak koji se tiče domaček zadatka, gdje je dakle imete instalaciju i dokumentaciju za JFlex alat koji ćemo danas bližo opisati, kao i videomateriale i izvorni kot koji se baš tiču leksičke analize za neku pojednostavljenu postavku projektnog zadatka. Tako da naremo kada budete krenuli sa izradom samo projektnog zadatka, svaka koja je dobro da pogledate taj video i da koristite izvorni kot kako biste prosto mogli da tada krenete, a onda ga naravno dopunjujete u skladu sa izmenjenom specifikaciju. Što sviče danasnjih materijala koji su vezani opet za ova alat, oni se nalaze u okviru vežbi kao V2, gdje imamo prosto JFlex prezentaciju i primere kao i kod uz te primere. Tako da ću vam i za početak kroz ovu prezentaciju viditi koja su neke ostavne funkcionalnosti, a paralelo sa tim ćemo proziti i kroz primer samog file koji predstavio neku specifikaciju leksičkog analizatora i naravno nakraju ćemo i neki primer pokrenuti kako bi smo datle sve to videli u praksiju. Jož jednom dakle cilj ove leksičke analize je da praktično uzme neki ulazni niska aktera koji se pojavi i da ih nekako transformiše u odgovarajuće tokene, gdje se dakle tistim boli koji se pojavljio na ulaznu identifikuju pomoću u regularnih izraza koji predstavljaju tako zvena pravila identifikacije. Gdje je na osnovu regularnih izraza dakle definišljamo šta su neke ključne reči ili opet kako formiramo odgovarajuće sekvence i kako ih klasifikojamo u neke tokene. U principu ideje da se niska aktera predstavi nekim simbolom, a sa druge strane, ukoliko ni jedan regularni izraz nije uspešno iskoriščen za prepoznavanje određene sekvence da se prijavi greška. To je tako zdoprim var neku ulaznu nizakaraktera, 12 abc.xx72, gdje bi smo naravno morali da specificiramo neke delimitere koje delere ječi koje ćemo kasnije klasifikovati, izlaz bi bio nisi simbola koji su klasifikovanji kao broj s enomeričkom vrednošću 12, word sa vrednošću abc, zatim dot koji predstavlja tačku, word koji ima vrednost xx i na kraju ješ jedan nambol, odnosno cejav broj koji ima vrednost 72. Da bi sve ovo moglo baš ovako da se prepozna, potrebno je napisati dakle formalnu specificaciju tog prepoznalanja i konkretno u ovom ovde dakle reći da u slučaj da nam dođe neka sequenza cifara od 1 do 9, odbar i jedne cifre, a moguće i više njih, vratićemo neki broj, dakle nešto što smo mi ovo značili kao broj, a zapravo videte ćemo kako je klasifikovan odnosno specificirano, gdje tajnji je kasnije, zatim naprimera ako je to neka sequenza odbar i jednog malog ili velikog slova englesku alfobeta, vratićemo reč, ukoliko recimo u pizanju tačka, vratićemo identifikator da je u pizanju tačka odnosno ovo dot i u supratnom, ako dobimo bilo što što nikako nismo mogli da uparimo u ove same izreze, vratićemo prosto da je to neka nevalidna sequenza. Prosto u ovom nekom konkretnom primero mi smo želi da prepoznamo dakle ili isključivo sequencu cifara od 1 do 9, ili malih ili veliki i slova englesku alfobeta ili tačku kao neki prosto poseban simul. Smista u svega ovoga je naravno da se pojednostavi rad parsera i generalno syntax na analiza, zato što prosto kao i kad smo pričali o pojmu transliteratora nema nikakog smisla da mi konkretno pravimo pravila i proverovamo konstrukcije poput 12 plus 32 puta 7, a onda nezavisno od toga recimo proverovamo 13 plus 32 puta 7, svojom suštini isti. Dakle, mnogo je bolje proveravati generičke konstrukcije poput ovde naprim. nekog broja plus broj puta broj, jer prosto dalje je u pitanju numerečkoj konstanta 12 litrina, s nama ovo vopšta nije bitno za to kako ćemo mi dalje procesirati taj izraz. Te sa te strane mi ovdom vopštavamo i pravimo više generičke konstrukcije kako bi smo kasnije prosto rosterati, ili parser, prilikom semantičke i syntaxne analiza. Ideja je, naravno, da se zadaju definicije regularnih izraza koja treba prepoznati, gde je onda prosto na osnovu tih konkretnih regularnih izraza, kao što sam već rekla, mi ćemo odlučivati, da li se radi u neku ključne reči ili u neku specifikaciji, dakle određenih racimo konstanti. I naravno je cilj da se iupravo izgeneriše izvorni kod klasi, koje će da vrši ovu celog kupnu leksičku analizu, na osnovu specifikacije koju mi prosto napiše. Sve to treba uprvo da nam uradi ove alat J-flex i ono što je naš prvi korak je da napišemo tu neku tekstuogno specifikacije u vidu neku file kojima ekstanzio flex i na osnovu koga se generiše java fan koji zapravo predstavlja sam lekser, odnosno scanner. Kako će se zapravo ovom koristiti? Na dalje o kompajleru su potrebni tokeni, tako da suštenski, ono što je izlaz iz ove leksičke analiza je njih z nekih klasifikovanih tokenu. Da bi to mohlo da se uradi, sa ulaza se čita niska aktera, a zatim se ti karakteri procesiraju na osnovu regularnih izraza, odnosno paternih. Paternih se mečuju i kreiraju se tokeni koji prosto odgovaraju tim ulazima. Na osnovu tih tokena dobijaju se dakle vrednosti i vraćaju se tako formirani simboli i oni se dalje procesiraju u narodnim fazama. Kao što sam da će rekl, prvi korak je napisati specifikaciju leksičke analize koje potrebna i ono se čuva kao flex file. Mora da se definiši šta su tu neki tokeni koji će dalje biti proslađivani. Osem toga se takođe piše i neka java klasa koji mi ovdje nazivamo sim koji će zapravo imati neke pojedinočne konstante koje će imitirati neke identifikatore. Kad budemo videli na samom primjero ja ću nešto detaljno objasniti kako se klasa formira i čemu je služi. U ovom momentu je dobrojno da znamo da ona postoji i da nam je još dodatno potrebno da upravo izgenerišemo skener, analizator u okviru nekog java programa, odnosno java file koji ćemo nazivati ovako. Kada smo go izgenerisali, imamo sve obkodne file i potrebno da ih prevedemo kako bi smo nakon toga pokrenuli cijel program, zada s bibliotekom koji koristimo za leksičko analizu. Što sviša samog leksičku file, on ima 3 neke sekcije. Prvo sekcije učine import iskazi, drugo sekcije učine odgovarajuće direktive J-flex, da ćemo vidjeti dakle koje su sve neke opcije, naravno više se možete i uputiti u samoj specifikaciji. I treć je predstavljaju možda i na interesantini del o pravihla za operiranje, uparivanje odnosno uprvo korišćenju ovih regularnih izgraza kako bi smo mečovali ulazne sekvence. Sam import iskazi služe da se prosto definiše koje pakete treba specificirati i koje treba uvesti i ako žalimo to dopodljodamo na nekom primero, najjednostavnije je to, dakle možemo vidjeti na dva primere gde jedan ćemo kasnije pokrenuti, ali on je jedan mali primer, da se da je sve te sve dej strane verovatno ne možemo mnogo toga videti ovde. Zbog toga sam ja uzala još jedan primer i to je baš one primer iz onog uvadnog kode vezanog za leksičku analizu, te praktično kada sa sajta preuzmete dakle video tutorial plus prateći izvorni kod, uzetete iz izvornog koda i pronaći leksički file gde bi trebalo da prosto možemo, da je on ipok dovoljno kompleksan, da možemo da vidimo preciznije, odnosno na primeru konkretnom uparimo ove sekcije samog file. Teg samim tim to je namo ova prva sekcija, i način svake u tih sekcija je ove i vjičeno s ova 2%. I ovde imamo neki import, dakle neke klase. Suštenske ono što će se deseti je da ova import baš bude i prepisan u rezultujiću java klasu za samo leksičku analizu prema ova specifikacija, zato što ova klasa će nam biti iz nekog razloga, potrebna kasnije u samoj specifikacija, ali dakle za sve te import iskaze koje ovde napišamo, oni će biti prepisani na sam početak file sa izvornim kodom tog analizator. Drugi del prestavio i JFlex direktive, to je sada sledaće naša sekcija, gde u principu moguće je napisati, odnosno specificirati ovu jednu kod sekciju, tako da sav java kod koji je tu navedam će direktno da se prepiše u ovu našu ciljnu klasu leksičku analizatora. I ako pogledamo kako je to ovdje izgledam, imamo uprvo jedno ovakav segment koda, gde je prosto jom o neke utility funkcije koja će kao takva biti prepisane u našoj ciljnoj java klasi. Naravno, obje direktive su neophodne, odnosno, vi delovi su neophodni da tako kažem, da bi prosto bilo jasno da taj segment koda treba interpli...
 odgvareći način. Moguće je naravno ta ideo kode ugraditi ili neka specificna mesta kao što su, recimo, konstruktori klasi električkog analizatora i to se deševa u slučaju da se dodatno daje uz direktivu i ovaj init, koji prosto onda kaže target mesto za premještanje, odnosno generisanje, odnosno prepisivanje, tako koda, upravo predstavlja sam konstruktor ove klase. Moguće i ovako nešto, a to je direktivu dopolniti ovim eof, odnosno end of file koji zapravo kaže da je ovo neki segment koda koji treba da se izvrši kada se dođe do kraja ulaznog file koji se zapravo obrađuje. Tako je to onaj input programski kod koji se obrađuje kad se dođe do njegovog kraja, dakle to je prosto neki kod koji treba izvršiti. Teste strane naravno moguće specificirati i neke jutilite stvari koja će kasnije biti korišće. Osem toga, u ovom modelju moguće je navoditi i makro definicije, gde se te definicije svakod njih navoda u zasebnoj lini i specificiraju suprvo ovako kao ime makroa jednako pa definicija gde ono što se mora ispoštovat je naravno da imena moraju biti neki ispravni identifikatori, a i da samo definicija mora imati ispravan regularni izraz. Dodatno u ovom modelku se takođe mogu navoditi i deklaracije leksičkih stanje. Sad stanja u principu predstavljaju, mislim, znamo, naravno žla za stanja, ali u ovom konkretnom slučiju, ono što imamo implicitno, to je inicijelno stanje programa i dakle, inicijelno stanje programa podrazumeva, normalno stanje programa u kome mi prosto pišemo neke izraze, očekujemo da će na tim izrazima dakle biti izvršena provere na svimi vojima koje imamo, da oni moraju biti ispravni u skladu sa specifikacijom jezika i da će naravno na kraju biti ispravno izvašeni. Osim tog inicijelnog stanja koja je implicitno postojeće u ovom leksičkom pilotu, samim tim nema potrebe za eksplicitim navođenje. Postoji ima učinost navođenja dodatnih stanja i evo u ovom konkretnom slučiju, mi imamo jedno dodatno stanje i to je stanje komentare. Dakle, sušljencki stanje u kome se obrada naših programa ponaša potpuno drugačije, pošto znamo da ono što je napisano u komentarima i jednostavno, naravno, nemora da odgovara nikakvo i našu specifikaciji, dakle nila eksičkoj tu su mogu nalaziti bilo kakvi neki karakteri, niti mora odgovara gramatici, niti bilo u čemu, te sa te strane, naravno, treba drugačije, odnosno odvojeno da prostoprocesiramo naš ulazni program. E, sada, kako ćemo mi dalje koristiti ovo stanje, o tom ćemo pričati malo kasnije, ali za sada je dobro da znamo da prosto u ovaj ovde sekcii se može koristiti i tako nešto. Što zifre našem projektom, mi ćemo uglavnom imati učevo ova dva stanja, ma za, naravno, moguće je uvoditi i više takvih stanja. Dodatno poslojaš neke direktive koje se ovde mogu koristiti. Recimo, to su direktive za brojnje linija, line, zato i za prebrojavanje karaktera i one se takođe navode ovde, dakle, mi imamo ove direktive ka-pline-colum. Za neke unjih ćemo kasnije videti čemu služe, međutim, u svakom slučaju, dakle, u koliku su vam potrebna još neke, u svobodom možete pogledati u pusvu, za J-Flags, dakle, postoji celokupno pusva za sve ove direktive. I naravno, postoji kompatibilni leksičke analizatori CAP, gde da bi se to sve obezpedilo, odnosno, moglo da se koristi. Odnosno, da bi se koristio ovaj neki simbol, kao klasa, ki objog te ćemo koristiti, umesto, standardno, tokena koji postoji, koristi se deklaracija CAP, to je ono što mi je ovde imamo, izahvaljujući koje možemo zapravo, da upravo uradimo ove ovde import i da koristimo ovu neku klasu simbolu, koje inicijalizujemo, odnosno objekte te klasi, inicijalizujemo na odgovarajući način, videt ćemo kasnije kak u zapravo pozivamo ove utility metode, ali ono što nam je u ovom trenutku značeno, a to je da zapravo da bi smo mogli da promenimo taj neki način tokenizovanja, odnosno da bi smo promenili zapravo kako opisujemo same tokene, mi smo ovde želi da koristimo nešto drugu, odnosno na taj standardni, wide wide token, i onda smo iskoristili ovu simbol klasu, a da bi smo nju mogli da koristimo, koristimo u prvo ovu deklaraciju, odnosno direktivu CAP. I treći naš deo, kao što revo, kvrvatno i najinteresantni deo ovog leksičkog filea, svaka koja nekome ćemo se najviše izadržati sa objašnjenjem, je ove treći koji upravo služi za specifikaciju regularnih istraza, koji ćemo je tako koristiti da bi smo prepoznavali ulazne sequence. Svaki taj regularni izraz ima opet neku svojom formu koju mora da zadovoli, i opšti oblik tok pravila je na početku specifikacija stanja, u kojima se primenjuje taj regularni izraz, gde ove specifikacija stanja je opciona, da se te strane ne mora postojati. U principu, ako se navode, to znači da se taj regularni izraz izključiovo primenjuje kada je neko stanje trenutno, odnosno kada se analizator nalazi u nekom od ovih stanja koja su nove dana u toj opcionalisti. Ukoliko ne postoji, ne mora ili tako, ne mora se specificirati. Nakon toga ide sam regularni izraz i nakon toga ide akcija. Predstavlja najčešće neki java kot koji zapravo se izvršava kada je prepoznat odnosno upareno odgovarajući regularni izraz na nekom uloznoj sekvenciju, i onda se od toga pravi neki token, to najčešće predstavlja našu akciju. Samo to uparivanje kreće od ozgora na njiže i u principu uparit, pošto kada bi smo sada pogledali na primeru, sve ovo ovde predstavlja to neko uparivanje. Gde ovde nemamo inicijalno tulisto stanja, ali nakon toga dolazio odgovarajući regularni izraz i nakon njega ova akcija koja specificira na ovim vititčastim zakradom. Samo uparivanje se dešava tako da zapravo na osnovu nekoj konkretnog niza simbola, koji su i vičeni i al tako belinamo, gde mi neki token želimo da prepoznamo, zapravo se pronaozi najduži regularni izraz koji al tako se uparuje i taj se naravno uzima. De postoji poklapanje, naravno ovde, dakle program, print, znači, de postoji poklapanje. Među ti možete, koliko postoji više ovih paterna, koji bi mohli da se uklope u prepoznavalje neko konkretnog tokena, onda će se i zabrati ovoj prvi poredosledu od ozgona njiže, zato što se prosto tim redosledom specificira takođi na neki način sam prioritet. I nešto više ću ovome kasnije ispričati, odnosno o tome koliko zapravo treba voditi računa o tome kojim redosledom se specificiraju ovih regularnih izrazi, zato što zapravo možemo i napraviti pometnju i iskoristiti neko opštije pravilo u mesto nekoj specificnije koje bi trebalo svakako dakle iskoristiti. E, naprimer, u koliku u nekom malom primercuću, mi želimo da, odnosno, nekom primercuću, tako mi želimo da prepoznamo jedno ili više cipara kao neki token ili jedno ili više malih slova mvesku alfabeta ili jednakost ili plus, prosto ćemo ovako navestite patterne i reći ćemo da je naša akcija da vratimo neki identifikator, 1, 2, 3 ili 4, zato što najčešći na osnovu toga šta smo pročetali, vraća se identifikator koji zapravo nosno u te povratne vrednosti, mi i onda nešto dalje radimo. Tako, te povratne vrednost, u ovom slučaju može biti običan celobroni identifikator, barem nešto počemu ćemo moći da razlikujemo šta smo mi to pročetili, a naravno u opštom slučaju želimo da napravimo malo kompleksnih u situaciju i sada ako pogledamo zapravo šta se ovdje nalazi, dakle mi zapravo poćemo da naprojimo neki internikot. Ostavimo to za sekund, samo da prođemo kroz sve šta mogu biti regularni izrazi. Onda smo da vidimo kako ih pišamo. Sami regularni izrazi nesmiju da sadrže bele karakter odnosno Belina, jer se se to suštenske tomaciti kao kraji izraza. I to ja smo pošto smo rekli da našli tukeni suupravo odvojeni tim Belinama. Već, uvrk, u koliko mi ba želimo da bele karakter bude u unutar tog regularnog izraza, osim za novi red, mošemo ga navesti, odnosno staviti ka po znake navoda i na taj način ćemo prosto izveći da to bude intertettirano kao kraj. U principu većina karakteri, ili gotovo, dakle svi karakteri, imaju oznacave sami sebe, međutim, postoje neki karakteri u koji imaju specijalne značenje, zato što se na posebe način koristav regularni izrazima u JFlexu i možemo ih videti upravo ovde, a videt ćemo i kakvo oni značenje imaju. Sada u kontaktu toga šta možemo predstaviti i regularnim izrazima, mi smo i pričali o tome na vešpama i samo konkatenaciju ne moramo nikako posebno osnačavati, dakle dovoljno da samo konkateniramo te delove sekvence. Što se tiče unije, prosto isto kao što smo radili na vešpama, uzmemo ovaj delimit.
 kao za ili. Ukoliko opcijno želimo da predstavimo neki deop sekvence, dakle 0 ili 1 pojevljivanje, dodajemo upitnik na kraj. Pozitivno zatvaranje označavamo plusom, dakle, poravljanje od 1 do beskonačno, naravno neki broj puta. Zvezdesto zatvaranje, zvezdi se mi odako. I u principu, navodnike možemo koristiti kako bi smo ove meta karakteri koji uvej u specijno značenje vratili u njihovo inicijalno značenje da bi izgubili, dakle, te svoje specijalno, odnosno posebne moće, tako nego da bi bili kao i svih drugi obični karakteri. I na kraju, u koliko želimo, bilo koji karakter da zamenimo, odnosno, pregutamo, odnosno, prepoznamo ili niz, odnosno, neku sekvencu karaktera, možemo koristiti tačku, kako bi smo to zamenili. U principu, naravno, da bi smo zamenili, odnosno, prepoznali posebne specijne karaktera, možemo ih i eksplicitno naglasiti. I kada podledamo kako to izgleda na samo u mojvom primero, vidat ćemo da, recimo, ako želimo da prepoznamo ključnu reču program, pa mi ćemo baš i da napišemo programi, al tako, zato što mi zapravo ovde prepoznamo u konkatenaciju baš karaktera ovih koji čine tu ključnu reču i baš u određenom poretku. Te samim tjim to je cijelo regularne izresko i ovde nama praktično treba. I to ćemo isto uraditi za ove neke druge ključne reči, a nakon toga, i za recimo plusi, jednako, tačku zarjez i tako neki posebne simbole koje takođe želimo da prepoznamo. Te sa te strane, dakle, njih navodimo eksplicitno, osim toga, možemo da uparavamo makro definicije, uniko znakove, aski, heksadecimalno-moktelnom broju i tako dalje. Kao što reko, kto sve možete pranaći u specifikaciji našto bliž. Osim toga, ovo što nam je možda posebno takođe interesantno su ove beline, zbog tog koji njih malo drugačije trajatiram. Ako primjetite, dakle, nakon svaku govog regulernog izreza, ukoliko uspešno mečujemo neki deo sekvence, mi imamo određenu akciju koja se dešava. E, u slučaju pro nalazka Belina, mi naravno ne želimo nikakvu akciju, ne želimo da se generiše neki javako, zato što prosto, dalje smo mi je u našem ulaznom programu kao programeri, napisali dva blanko razmaka ili jedan, nema sušnjenske nikakvog utica, niti na bilo kakvu analizu i provjeru samo kod, da se niti na arvanom njegovog generisanje, tako da u slučaju da imamo blanko znak ta prelazak u naravni red, dakle mi ćemo prosto specipicirati da akcije nema baš ovako. U sluprotnom trebanom neka posebna akcija. I sada ovdje su dati tekođe i neke primjeri regulernih izreza, gde možemo obuhvatiti neke sekvence, pa ih ne napisati baš onako eksplicitno, i ukuliko recimo, koćemo da predstavimo bilo koje malo slovo, to ćemo uraditi ovako. Tako što ćemo u ovim uglastim zagredama reći od aduce, dakle nećemo svakako navoditi a, b, c, d i tako dalje, to bi bilo naravno potpuno nepraktično, taj samim tim ovako navodimo praktično jedan obseg. S druge strane recimo, možemo koristiti i ovu kapicu kao compliment, i ukuliko ukljećemo da kažemo da prepoznamo sve izuzevci para, mi ćemo to nam vlasiti, tako što ćemo staviti tu kapicu i nakon toga obsega od 0 do 9, što znači prepoznamo sve osim toga obsega od 0 do 9. Ako koćemo da prepoznamo bilo koju heksa decima u cipru, navišćemo recimo ovakva 3 obsega, gde je prva cifra je otak od 0 do 9, nakon toga malo a do f ili veliko a do f, i do prostu zbog toga što ne želimo da budemo kaj sensitiv. Ili recimo na primer baš u kolikom želimo da izbegnemo obseg, korišćenjemu, ili tako ove crtice, već želimo eksplicitno da koristimo crticu, onda videli smo da te metak karakteri gube svoje posebno značenje, tima što ćemo ih oivićiti navodnicima, jer se recimo u koliko u okvoru navodnika napišemo o 0 do 7, pa to će objevozno, samo značiti da možemo upariti sa a ili sa crticom ili sa set, dakle nema više to svoje posebno značenje. E sad, osim toga moguće je naravno specificirati i neka pravila prepoznavanja, te recimo u ovom slučaju možemo prepoznavatiti neke identifikatore i to će nam je biti od neku značaja, zato što vide ćemo, dakle ovde, osim ovi konkretnih ljučnih rekčipa, mi želimo da prepoznamo i nešto ćemo da koristimo u našim programu, o što ne znamo u naprit, kako će vrednosti tačno imati, numeričke konstante, čar konstante, sringove, identifikatore i to ćemo raditi upravo ovim regularnim izrazima. Ten, na primer, ovdje imamo specifikaciju za dva, neka tako uopšte na regularna izrsa, u koliku želimo da prepoznamo celobrenu konstantu, onda ćemo da kažemo, pa to ćemo uzeti kao cifre od 0 do 9, a u koliku želimo da prepoznamo neki identifikator, to ćemo prepoznaći ovako nekim izrazom, samo pri toga bih rekla da recimo, u koliko želimo da naš numerički identifikator počnem, obavezno, jedinico, onda recimo možemo da kažemo i ovako, a nakon toga recimo, ako hoćemo da imamo ovde prepoznavanje kao niz cifara, pa da kažemo počnje sigurno od 1 do 9, a nakon toga možemo imati 0 ili više ponavljenje od ovih ili recimo, ako nam to nije toliko bitno, onda možemo i da kažemo, pa dobro ponavlja nam se od 0 do 9 barem 1, a potencijalno više puta. Ove druke i ovde izraz predstavljenom parivanje nekog identifikatora, gde specificiramo da on kreće malim ili velikim slovom, englasku alfobeta odado set, a nakon toga može a nemora doći ili malo ili veliko slovo ili cifra ili doňa crta. Dakle, mi specificiram ovim da naš identifikator mora početi malim ili velikim slovom, a nakon toga mogu a nemora i doći malo veliko slovo cifra ili doňa crta. Tje samim tim dakle za sve što nam je tako potrebno da nekako posebno uparimo, mi ćemo ovde zapravo i pisati takav neki malo kompleksni, regularni izraz. Što se tiče samih akcija, akcija prestavaju neki java kod, i taj kod se zapravo izvršava nakon što se je tako prepozna odgovarilići regularni izraz, odnosno uparis. Zato, ono što je glavni tiđa akcija zapravo je da se tu vrati neka povratna informacija, koja će zapravo nama reći šta smo mi to prepoznali na ulazu. I sada to može biti u nekom najjednostavnjem slučaju, kao što je, recimo, dato u konkretnom ovom primaru, neka obična numerička konstanta, međute, može biti malo kompleksni stvar, pa recimo, o to neki, onaj baš interni kod, gde ako se svećete, rekli smo, u okviru tog interno koda, imamo klasifikaciju i imamo samu vrednost konkretnog toga što smo pročitali i prepoznali. Klasifikacija ovde se radi na osmogu neke numerečke konstante, koje opet treba da nam kaže šta smo mi to konkretno prepoznali i kao što možete primjetiti i u okviru ovog filea, a i u okviru ovog jednostavnjima, zato smo koristili uprvo ovu sim klasu, i rekli smo da ću to malo kasnije objasniti, poslade pravo vreme za to. Dakle, ovu sim klasu koristimo kao prosto neku neke popis svih tih numerečkih konstanti, koji zapravo svaka pojedinočna označava jednu tu klasu koji možemo prepoznati. I odvajamo je u principu za svaku, ovu stvar koji smo mogli da uparimo, da bi smo na jedno značen način, mogli praktično da kažemo šta smo mi to prepoznali i šta smo mi to vratili. Te tako, u ovom kompleksnim programu, svaki put kad radimo neko uparivanje, vratićemo neki internikod identifikovan upravo na klatom nekom numerečkom jedinstvenom konstantom i vrednošću koja je pročitena sa samog ulaza. Sada se možemo vratiti na ono goreš, to smo bili privrmeno preskočili i vidimo da zapravo taj simbol koji mi ovde pravimo taj objekat nekoj simbola proslajđujemo mu upravo taj identifikator i neku vrednostu ukliko je potrebno ili nemaramo, a to odvajamo ovde se sad proslajđu ili linije i kolonizmu o prijatljivanje greški, ali to nam o ovom momentu nije baš ni toliko značajno. One što bih još dodala u ovom momentu je ova tačka koja je smestana na sam kraj filan i upravo je korelesano to sa onim prepoznavanjem koje sam rekla da ide o dozgo na niže, gde ova tačka ima to svoje specijalno značanje, to je da će da upar i bilo koji simbol, odnosno znak na ulasu ili sekvencu. Međutim pošto prepoznavanje ide od nespecificnih kao opštijem i od ozgo na dole, u principu ovo tačko ćemo prepoznavali samo u koliku prepoznavanje nije uređeno nipo jedno i drugo i smedni, odnosno nipo jednom drugom patternu. Tesa, te strane njen cilje upravo da na kraju, ako ništo drugo nije prepoznavo kaže došle do leksičke greške, našli smo na ulazu na nešto što nismo predvideli o ovom našem specijkacijom i prosto prijavljuje se neka greška u okurte akciju, ako se ispisuje.
 Što se tiče sameh metoda koja su vidjive u okviru tih akcija, primetili ste da imamo racimo ovu metodu, šta je njen cilj? Njen cilj je da vrati neki tekst koji je pročetan na ulazu i da sami tim to je praklično presavljicializaciju vrednosti ovo konkretnog objekta. Često to će nam biti koristno, na primjer, vratimo ovaj neki identifikator, klasifikovali smo go kao identifikatorom ovom nekom numerečkom oznakom, međutim također nam treba naravno i njegovakonkratna vrednost i to ćemo ovde vratiti i moći ćemo da iščupam. Isto tako. U slučaju, ove celobrojne konstante vratit ćemo numerečku vrednost koji ćemo inicializuvati ovom što smo pročetali sa ulaza, tenam se te strane koristi tekst. Isto tako, na primer, ovo koristimo za objelažavanje linije, te imamo ove neke posebne metode i promenljive koje možemo da koristimo. Osim toga, postoji ove metoda koja se koristi za preles zaku druga stanja i to je upravo, naravno, one sada deho, da mi zapravo treba da je skoristimo ideju što smo ovde implementirali, odnosno, na značili da imamo dva stanja, jedno je inicijano i ovo drugu koje se odnosi na stanje komentar. Te upravo tom akcijam i kažemo, implicitno, naravno, krećemo u inicijavnom stanju, to nikt ne ne naglašavamo, to je prosto jasno uve krećemo od ovoj neko gini cijelomog stanja. Međutim, nakon doga, odismo, dakle, obređivali skučivo jednolijnijski komentar i onda kažemo, pa dobro, kada dođemo do... slash slash, ili tako, prepoznavanja, mi prelazimo u novo stanji i to je stanje komentar. E sada, kako dalje procesiramo to o stanji i kako se vraćemo u inicijavno stanji? Za to imamo ove dve... naše... tako naše regularne izraza, koja sada vidite imaju i onej prvi del koji bio opcioni i koji se odnosi na samostanji, što znači da se one zapravo koriste i sključevo u slučaju, kada se malo se nalazimo u stanju komentar. Te kada smo u stanju komentara, pojavljuje se bilo šta, mi kažemo, ostajemo u stanju komentarom. Međutim, kada pređemo u narodnih red, što je, mohno što se ne odnosio, tako, na što se ne odnosio ova tačka, mi zapravo, pušto bio jednoliniški komentar, vraćemo su ono naše inicijavno stanje. Ovo nam znači zbog toga, što ne radimo ove prepoznavanja u okviru stanja komentar, da će sključevo u okviru inicijavnog stanja, izbog toga prosto mogućevamo da u tom stanju komentar piszemo i neke druge stvari, koje možda ne bi bila u skladu, naravno, sa ovom analizom i naravno se dalje i ne proveravaju. Ok. U principu, ovdje smo dakle videli sada na jednom primjero, file, kako to funkcioniša, šta su to neki sve segmenti, koje je potrebno da vi implementirate. Dodatno, osim toga, naravno, imaćete čitav spisak nekih ključnih reći koje potrebno podržati. Možda je još neke dodatne regularne izraze, koji ima je potrebno proširiti ovaj ovdje file. Međutim, kada prosto razumete, kako funkcionišu sve se u svom sečem, kada prosto razumete, kako funkcionišu segmenti ovog ovdje file, ovdje bi to trebalo da bude prilično jednostavno i da bude ok. Sada ćemo pogledati još i jedan primjer. U principu, ti primjeri se nalaze, kao što sam rekla, na samom sajtu. Baš ovde kod u ZJFLAX primjera, tako da opovazno to preuzmite. Pogledajte sami primjere, mi ćemo pokrenati primjer tri čisto, da bi bila jasno kako se to radim. Međutim, u okvoru ovog file generatori leksičkih analizatora imate nekoliko različitih zadačića i primjera. Ja savjetuju da svakak u kroz to prođete. Da bi vam prosto bilo jasnijem, mi ćemo odraditi sada jedan od tih primjera. Što siča samo konkretno primjera, već smo videli, segmenti on je jako jednostavan. Bazira se na prepoznavanju, isključimo nekih aritmetičkeh izraza, međutim, sastavljenih samo od celobrnih konstanti, imaju otvrne zatvrne zagrede, sbiranje množenje, ataku zaraz i u principu, ako se pojave, bilo šta drugo na ulazdu, to će biti prijavljeno kao i legalni karakter. Šta nam se nalazi? Ja sam naravno to preuzela, raspokovala sam ovakav nekih podiri, kad pogledamo šta tu imamo. Vidimo da imamo neki biblioteki, gde jedna je ovo biblioteka J-Flux, koji ćemo sada koristiti i drugi su ove dve dodatne biblioteki, JUnit i Java Cup. Gde videli smo da ta Java Cup nam takođe služi za ono podršku? Da koristimo simbol. U ovom jednostavnom prvom slučaju mi nećemo koristiti ove dve druge bibliotekje i z prostog razloga što nam nije potrebno. Ovde prosto vraćemo samo numerečke konstanci, ne vraćemo one simbolu, tako da nemo potrebe za tom dodatno bibliotekom. U nekim drugim primirima će možda biti potrebe, pa se ona nalazi tu. A kao što rekl, mi sada radimo primer 3, pa hajde da vidimo, dakle šta tu sve imamo. Dakle, imamo ove FlexFalco i predstave specifikaću, imamo ove neki primer, koji treba da vidimo šta radi, imamo, naravno, sim klasu, u koji smo već videli, ako je zapravo numerišel tako ove konstante i na osmog u kojem možemo da razlikamo konkretne tokene sa ulaza. Kada pogodamo šta nam radi u ove primer 3.java, vidimo da on ima neki main, ili tako potreba nam je main ovoj naše programa, gdje je zapravo pravimo ove lekser, kao baš ovoj java klasu koji smo rekli da nam je cilj da izgenerišemo, međutim trenutno je nemo. Tako to je naš prvi korak da izgenerišemo opravu ovu klasu leksera. Šta ćemo dalje da radi? Čitamo token po token sa ulaza, zada sveduk ne dođemo do kraja fila i na neki način ga obrađemo. Sada u samo ove metodi obrada, cilje je prosto da vidimo šta smo mi to dobilili od leksičkog analizatora i da kažemo, dobra, za svaku u dobi konstanti koji smo dobilili, hajde samo da je ispisamo nešto. I ono što vidimo do ovom slučaju, dakle ispisujemo zakonkretan simbol klasifiku, kojemo ga kao simboli pisamo plusi puta, za neku numerečkom osantu ispisujemo samo da pripadam broju, a u slučaju i zagrde ispisujemo leva i desna. Dodatno, također moguće je ovde napraviti podrešku za hvatanje iz uzeta, kada je naravno ako bi smo oklužili trajka i kač blokom, u koliko dođe do neke greške prilike om obrade, mogre bi smo naravno to da uhvatimo. Ok, način prvi naš zadateki upravo da izgenerišemo ovu ovde klasu pošto kako smo videli, trenutno je nemovo. Kako ćemo da izgenerišemo? Tako što ćemo da iskoristimo baš ovaj J-flex-džar, kako bi smo izgenericali tu našu klasu, tako da potrebno je da tom džaru prosledimo specifikaciju našeg leksičkog analizatura, na snu koja ćemo ga napraviti. Ta naša specifikacija se nalazi u okviru ovog primera 3 i to je uprvo ovaj naš flex file. I ono što vidimo sada da so ovde desilo, jedan zapravo je iščitana, ovaj ovde file iščitana i na ostavu njega je konstruisano prvo ne deterministrkik konočni automat, nakon toga je ono prevedano deterministrkik konočni automat i mi smo zapravo na ostavu od toga sprovedana neka minimizacija uzpot i na ostavu od toga smo formirali ovaj ovde file. Tako da ono što je jasno, zapravo ovde file funkcioniše i zapravo jedan konočni automat i u principu na ostavu od toga naravno ide neko prepoznavanje. Za sveće stvar koji treba da uradimo. Je naravno, ono što je namo ultimativni cilj ovde je da je izvršimo ovaj ovde maina, da bi smo mogli da ga izvršimo i naravno moram prevedamo ove fileve. E sada da bi smo mogli da ih prevedamo, dakle prevodimo ove primera 3 i ala. Gde naravno kada sada vidimo šta se tu zapravo desilo vidimo da smo dobili class file za primera 3, takođe smo naravno dobili class file za sim i za ovo izgenerisan naš analyzator zato što su to dependensiji i u principu ono što je ostalo i još da samo izvršimo ovde program i da vidimo šta će da se desi i izvrši ćemo ga o što ćemo da kažemo izvršavamo primera 3 i sada šta se desa u ovom našem programu pa on zapravo naš čeka da nešto u nasamo sa ulaza al tako videli smo šta ono koće da prepozna al tako koće da prepozna neke numeričke konstante i možemo recimo da kažemo 2 plus 5 i on će al tako da uzme i da pogleda svaki od stih konkretnih simbola i da kaže dobro da smo pareli kao broj zatim smo našli symbol plus i nakon toga smo našli takođe neki broj i to je ono što je ono chteo da prepozna u skladu su u prvo ovom ove specifikaciju međutim naprimer da smo izabrali nešto drugo što prosto ne postoji u ovaj ovoj specifikaciji da smo recimo, rekli 2 minus 5 našli bi smo od tako na broj pa nakon toga ilegalni karakter i nakon toga broj zato što normalno on je došao do ovoga krenove prepoznavenje od vrha nije nigde uspio da upari određeni simbol ovoj minus i došao do ove tačke prosto to je prijavio kao neki ilegalni karakter inače, ovaj se dobro mesto da napomjenim ono što sam zaborila da se, našto sam zaborila se vratim
 u rove veći neki specifikacije, a to je da kažem da ove rade sledi jako bitan, naprimer, u koliko imete podrešku za buljevom promendive i onda koćete da obezbedite naravno tru i folska uključne reći. Bitno je pozicijeno i da ćete ih smestiti, jer ako ih recimo, smestite negde ovde gore, to je u redu, nakon tole doze identifikatori. I onda, praklično, ako vi negde specificirate tru u samom programu, to će biti upravo prepoznetu kao i ono što ste želili, a što je ključni reć. Međutim, ukliko prvo naglasite da postoji identifikator, koji može, kao što vidimo, da se stoji sključiv od slova, a nakon toga u našu specifikaciji dođe, recimo, tru kao ovako specificjna reć, to će biti problem, zato što će ono prvo biti prepoznat kao identifikator i nećete ga zapravo nikad prepoznati onako kako ste želili. Tako da zbog tova, obracite pažnju na ovaj ovde red. E, dakle, mi smo sada ovde uspjerno uspeli da izvršimo taj naš program, dakle, sifikujamo ove odgovarajće simbole sa ulaza. Vi, naravno, kao što reku, prođite i kruzone drugi primere i na osnovu ovoga bi prosto trebalo da bude jasno šta smo mi radili u ovom nekom prvom segmentu i kao što reko, šta će biti zadatak naše prve faze u konstrukciji minicompajlera.
